# -*- coding: utf-8 -*-
"""WeatherForecaster5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ge6rO1EQ-V4w6Rnhw26OB5gamhFWWWAE
"""

# === Weather Forecaster v5 by Amraj Takhar ===

# --- Import libraries and files -----------------------------------------------
csv_path = "/content/NYCDataset.csv"

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import timedelta
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

# --- Test if TensorFlow works. If not, use something else ---------------------

use_tensorflow = False
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
    from tensorflow.keras.callbacks import EarlyStopping
    use_tensorflow = True
except Exception:
    use_tensorflow = False

# --- Imports Multi-Layer Perceptron regressor, the something else -------------

from sklearn.neural_network import MLPRegressor

# --- Loads and cleans the data in the csv file, proper formatting, ------------
# --- chronological dates, numerical columns, etc. -----------------------------

df = pd.read_csv(csv_path)
df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')
df = df.sort_values('datetime').reset_index(drop=True)
df = df[~df['datetime'].isna()].copy()

numeric_cols = ['tempmax','tempmin','temp','humidity','precip','precipprob',
                'windgust','windspeed','sealevelpressure']
for c in numeric_cols:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors='coerce')
df[numeric_cols] = df[numeric_cols].fillna(method='ffill').fillna(method='bfill')
df['date'] = df['datetime'].dt.date

# --- What features/targets (inputs/outputs) is my model using -----------------
# --- Also prevents high precip values from skewing the model. -----------------

features = [f for f in ['temp','tempmax','tempmin','humidity','precip','windspeed','windgust','sealevelpressure'] if f in df.columns]
targets = [f for f in ['precip','humidity','sealevelpressure','windspeed','windgust'] if f in df.columns]

data = df[['datetime'] + features].copy().reset_index(drop=True)
if 'precip' in data.columns:
    data['precip'] = np.clip(data['precip'], 0, np.percentile(data['precip'], 99))

# --- Preparing the data for time-series modeling. Window size looks back ------
# --- 14 days is best, doesn't decrease val_loss much. -------------------------
# --- Also prints how many training samples/features/outputs there are ---------

window_size = 14
X_list, y_list, dt_list = [], [], []

for i in range(len(data) - window_size):
    window = data.loc[i:i+window_size-1, features].values
    X_list.append(window.flatten())
    y_list.append(data.loc[i+window_size, targets].values)
    dt_list.append(data.loc[i+window_size, 'datetime'])

X = np.array(X_list)
y = np.array(y_list)
print(f"Training samples: {len(X)} | Features per window: {len(features)} | Outputs: {len(targets)}")

# --- Predicts the daily temperature a week ahead, forecasts future days. ------
# --- Uses simple linear trends, falls back if not enough data. ----------------

def forecast_daily_avg_temp(df, days_ahead=7):
    daily = df.groupby('date')[['temp','tempmax','tempmin']].mean().dropna().sort_index()
    if len(daily) >= 7:
        n_fit = min(14, len(daily))
        daily_fit = daily.iloc[-n_fit:]
        avg_coef = np.polyfit(np.arange(len(daily_fit)), daily_fit['temp'], deg=1)
        max_coef = np.polyfit(np.arange(len(daily_fit)), daily_fit['tempmax'], deg=1)
        min_coef = np.polyfit(np.arange(len(daily_fit)), daily_fit['tempmin'], deg=1)
        x_next = np.arange(len(daily_fit), len(daily_fit)+days_ahead)
        return (
            np.round(np.polyval(avg_coef, x_next), 2).tolist(),
            np.round(np.polyval(max_coef, x_next), 2).tolist(),
            np.round(np.polyval(min_coef, x_next), 2).tolist()
        )
    else:
        last_avg = daily['temp'].iloc[-1] if len(daily) > 0 else df['temp'].iloc[-1]
        last_max = daily['tempmax'].iloc[-1] if len(daily) > 0 else df['tempmax'].iloc[-1]
        last_min = daily['tempmin'].iloc[-1] if len(daily) > 0 else df['tempmin'].iloc[-1]
        return [round(float(last_avg),2)]*days_ahead, [round(float(last_max),2)]*days_ahead, [round(float(last_min),2)]*days_ahead

# --- Adds fallback if there's not enough samples in the dataset. --------------
# --- Prepares the data for training. ------------------------------------------

if X.shape[0] < 50:
    print("\nNot enough samples for DNN. Using persistence fallback.")
    last_row = data.iloc[-1]
    today = pd.Timestamp.today().normalize().date()
    future_dates = [today + timedelta(days=i) for i in range(7)]
    persistence_preds = pd.DataFrame({
        'date': future_dates,
        **{t: [last_row[t]]*7 for t in targets}
    }).round(2)
    display(persistence_preds)

else:
    split_idx = int(0.8 * len(X))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]

    scaler_X = MinMaxScaler().fit(X_train)
    X_train_s = scaler_X.transform(X_train)
    X_test_s = scaler_X.transform(X_test)

    scaler_y = MinMaxScaler().fit(y_train)
    y_train_s = scaler_y.transform(y_train)
    y_test_s = scaler_y.transform(y_test)

    # --- Checks if tensorflow is enabled, reshape the inputs, clears previous
    # --- sessions. Defines the LSTM model to be used, compile it. Stop the
    # --- model early if val_loss doesn't improve within 10 epochs.
    # --- Then train the model and print how many epochs used before early
    # --- stop triggered.

    if use_tensorflow:
        n_features = len(features)
        X_train_seq_s = X_train_s.reshape(-1, window_size, n_features)
        X_test_seq_s = X_test_s.reshape(-1, window_size, n_features)

        tf.keras.backend.clear_session()
        model = keras.Sequential([
            layers.Input(shape=(window_size, n_features)),
            layers.LSTM(96, activation='tanh', dropout=0.2, recurrent_dropout=0.1),  # dropout randomly ignore 20% of inputs to lessen overfitting
            layers.Dense(48, activation='relu'),                                     # rec dropout randomly ignores 10% of recurrent connections
            layers.Dense(len(targets), activation='linear')
        ])

        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        early = keras.callbacks.EarlyStopping(
            monitor='val_loss',         # stop when validation loss stops improving
            patience=10,                 # wait for 5 epochs of no improvement
            min_delta=1e-4,             # minimum change to qualify as improvement
            restore_best_weights=True,  # revert to best weights
            verbose=1                   # show a message when stopping
        )

        history = model.fit(
            X_train_seq_s, y_train_s,
            validation_split=0.15,
            epochs=60,
            batch_size=32,
            callbacks=[early],
            verbose=1
        )

        print(f"\nTraining stopped after {len(history.history['loss'])} epochs.")


        # --- Make predictions with the trained LSTM, calc MAE + RMSE, then
        # --- print the results. -----------------------------------------------

        y_pred_s = model.predict(X_test_seq_s)
        y_pred = scaler_y.inverse_transform(y_pred_s)
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        print(f"\nModel Evaluation: MAE = {mae:.3f}, RMSE = {rmse:.3f}")

        # --- Creates multi-day forecasts using trained LSTM (a week) ----------

        last_window = data[features].iloc[-window_size:].values.copy()
        future_preds = []
        today = pd.Timestamp.today().normalize().date()
        future_dates = [today + timedelta(days=i) for i in range(7)]

        for _ in range(7):
            flat = last_window.flatten().reshape(1, -1)
            flat_s = scaler_X.transform(flat)
            flat_seq_s = flat_s.reshape(1, window_size, n_features)
            pred_s = model.predict(flat_seq_s).ravel()
            pred = scaler_y.inverse_transform(pred_s.reshape(1, -1)).ravel()
            future_preds.append(pred)
            new_row = last_window[-1].copy()
            last_window = np.vstack([last_window[1:], new_row])

        future_preds = np.array(future_preds)
        pred_df = pd.DataFrame(future_preds, columns=targets)
        pred_df['date'] = future_dates
        pred_df[targets] = pred_df[targets].round(2)

        # --- Calculates Rain Chance -------------------------------------------
        if 'precip' in pred_df.columns:
            max_rain = max(pred_df['precip'].max(), 0.5)
            pred_df['rain_chance_%'] = np.clip(100*pred_df['precip']/max_rain, 0, 100).round(2)

        # --- Displays the two tables showing the weekly data ------------------
        print("\n=== Weekly Forecast Summary ===")

        # Round all numeric columns to 2 decimal places
        numeric_cols_pred = pred_df.select_dtypes(include=np.number).columns
        pred_df[numeric_cols_pred] = pred_df[numeric_cols_pred].round(2)
        pd.options.display.float_format = '{:.2f}'.format

        # Display table
        display(pred_df[['date'] + targets + (['rain_chance_%'] if 'rain_chance_%' in pred_df.columns else [])])

        temp_forecasts_avg, temp_forecasts_max, temp_forecasts_min = forecast_daily_avg_temp(df, days_ahead=7)
        temp_df = pd.DataFrame({
            'date': future_dates,
            'avg_temp': temp_forecasts_avg,
            'max_temp': temp_forecasts_max,
            'min_temp': temp_forecasts_min
        }).round(2)
        display(temp_df)


        # --- All Plot Code ----------------------------------------------------

        # Temperature
        plt.figure(figsize=(9,4))
        plt.plot(temp_df['date'].astype(str), temp_df['avg_temp'], marker='o', label='Average')
        plt.plot(temp_df['date'].astype(str), temp_df['max_temp'], marker='o', label='Max')
        plt.plot(temp_df['date'].astype(str), temp_df['min_temp'], marker='o', label='Min')
        plt.title("Weekly Temperature Forecast (°F)")
        plt.xlabel("Date")
        plt.ylabel("Temperature (°F)")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()

        if 'rain_chance_%' in pred_df.columns:
            plt.figure(figsize=(9,4))
            plt.plot(pred_df['date'].astype(str), pred_df['rain_chance_%'], marker='o')
            plt.title("Weekly Predicted Rain Chance")
            plt.xlabel("Date")
            plt.ylabel("Rain Chance (%)")
            plt.grid(True)
            plt.tight_layout()
            plt.show()

        for col in ['humidity','sealevelpressure']:
            if col in pred_df.columns:
                plt.figure(figsize=(9,4))
                plt.plot(pred_df['date'].astype(str), pred_df[col], marker='o')
                plt.title(f"Weekly Forecast: {col.capitalize()}")
                plt.xlabel("Date")
                plt.ylabel(col.capitalize())
                plt.grid(True)
                plt.tight_layout()
                plt.show()

        # Wind speed + gust
        plt.figure(figsize=(9,4))
        if 'windspeed' in pred_df.columns:
            plt.plot(pred_df['date'].astype(str), pred_df['windspeed'], marker='o', label='Wind Speed')
        if 'windgust' in pred_df.columns:
            plt.plot(pred_df['date'].astype(str), pred_df['windgust'], marker='o', label='Wind Gust')
        plt.title("Weekly Wind Forecast")
        plt.xlabel("Date")
        plt.ylabel("Wind (mph)")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()

        # Training vs Validation Loss
        plt.plot(history.history['loss'], label='train')
        plt.plot(history.history['val_loss'], label='val')
        plt.legend()
        plt.title("Training vs Validation Loss")
        plt.show()

        # --- TFLite export ---
        converter = tf.lite.TFLiteConverter.from_keras_model(model)
        converter.experimental_new_converter = True
        converter.target_spec.supported_ops = [
            tf.lite.OpsSet.TFLITE_BUILTINS,
            tf.lite.OpsSet.SELECT_TF_OPS
        ]
        tflite_model = converter.convert()
        with open('weather_prediction_model.tflite', 'wb') as f:
            f.write(tflite_model)
        print("TFLite multi-output model saved as weather_prediction_model.tflite")

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

def evaluate_model(y_true, y_pred, targets):
    results = {}
    for i, col in enumerate(targets):
        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])
        rmse = np.sqrt(mean_squared_error(y_true[:, i], y_pred[:, i]))
        r2 = r2_score(y_true[:, i], y_pred[:, i])
        results[col] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}
    return results

# Example usage:
metrics = evaluate_model(y_test, y_pred, targets)
for feature, vals in metrics.items():
    print(f"{feature}: MAE={vals['MAE']:.2f}, RMSE={vals['RMSE']:.2f}, R2={vals['R2']:.2f}")

def plot_predictions(y_true, y_pred, targets, n_days=30):
    plt.figure(figsize=(12, 6))
    for i, col in enumerate(targets):
        plt.plot(y_true[-n_days:, i], label=f'Actual {col}', marker='o')
        plt.plot(y_pred[-n_days:, i], label=f'Predicted {col}', marker='x')
    plt.title("Predicted vs Actual")
    plt.xlabel("Days")
    plt.ylabel("Value")
    plt.legend()
    plt.grid(True)
    plt.show()

# Example:
plot_predictions(y_test, y_pred, targets)

from sklearn.metrics import brier_score_loss

# Convert predicted precip to "rain yes/no" (threshold 0.5mm)
y_true_rain = (y_test[:, targets.index('precip')] > 0.5).astype(int)
y_pred_rain_prob = y_pred[:, targets.index('precip')] / max(y_pred[:, targets.index('precip')].max(), 0.5)
brier = brier_score_loss(y_true_rain, y_pred_rain_prob)
print(f"Brier score for rain prediction: {brier:.3f}")